{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaygensmann/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15061,\n",
       " 27025,\n",
       " 27013,\n",
       " 15025,\n",
       " 33070,\n",
       " 27063,\n",
       " 15076,\n",
       " 33021,\n",
       " 33023,\n",
       " 27038,\n",
       " 15049,\n",
       " 33039,\n",
       " 15081,\n",
       " 27005,\n",
       " 33069,\n",
       " 27002,\n",
       " 33017,\n",
       " 33018,\n",
       " 15055,\n",
       " 33030,\n",
       " 33019,\n",
       " 39047,\n",
       " 39006,\n",
       " 27027,\n",
       " 39011,\n",
       " 27033,\n",
       " 33074,\n",
       " 33056,\n",
       " 15051,\n",
       " 39005,\n",
       " 39043,\n",
       " 39061,\n",
       " 33013,\n",
       " 27061,\n",
       " 33077,\n",
       " 33010,\n",
       " 39029,\n",
       " 33007,\n",
       " 27030,\n",
       " 48012,\n",
       " 39044,\n",
       " 39009,\n",
       " 33009,\n",
       " 15015,\n",
       " 39040,\n",
       " 33054,\n",
       " 48056,\n",
       " 33065,\n",
       " 33059,\n",
       " 33063,\n",
       " 39062,\n",
       " 48068,\n",
       " 48014,\n",
       " 48077,\n",
       " 48031,\n",
       " 39031,\n",
       " 33042,\n",
       " 48076,\n",
       " 39036,\n",
       " 48048,\n",
       " 39076,\n",
       " 39080,\n",
       " 39024,\n",
       " 48021,\n",
       " 48061,\n",
       " 39068,\n",
       " 48028,\n",
       " 39028,\n",
       " 39084,\n",
       " 48089,\n",
       " 39095,\n",
       " 39099,\n",
       " 33055,\n",
       " 33045,\n",
       " 39038,\n",
       " 39001,\n",
       " 27001,\n",
       " 48064,\n",
       " 48040,\n",
       " 48049,\n",
       " 33071,\n",
       " 27054,\n",
       " 33040,\n",
       " 48033,\n",
       " 39102,\n",
       " 27021,\n",
       " 48908,\n",
       " 39030,\n",
       " 48053,\n",
       " 48041,\n",
       " 39048,\n",
       " 27048,\n",
       " 48913,\n",
       " 48063,\n",
       " 15091,\n",
       " 39002,\n",
       " 39037,\n",
       " 48010,\n",
       " 39064,\n",
       " 39090,\n",
       " 48907,\n",
       " 33043,\n",
       " 48906,\n",
       " 48047,\n",
       " 33029,\n",
       " 33006,\n",
       " 39091,\n",
       " 48035,\n",
       " 48004,\n",
       " 15050,\n",
       " 15043,\n",
       " 39018,\n",
       " 48909,\n",
       " 33046,\n",
       " 48079,\n",
       " 48018,\n",
       " 39019,\n",
       " 48903,\n",
       " 48038,\n",
       " 48914,\n",
       " 33075,\n",
       " 33047,\n",
       " 39033,\n",
       " 33057,\n",
       " 20056,\n",
       " 39058,\n",
       " 20039,\n",
       " 48911,\n",
       " 27044,\n",
       " 48904,\n",
       " 33008,\n",
       " 33064,\n",
       " 39056,\n",
       " 39041,\n",
       " 48066,\n",
       " 48070,\n",
       " 20029,\n",
       " 48067,\n",
       " 15064,\n",
       " 15039,\n",
       " 48062,\n",
       " 48905,\n",
       " 33038,\n",
       " 33005,\n",
       " 39067,\n",
       " 31250,\n",
       " 33078,\n",
       " 39045,\n",
       " 39069,\n",
       " 39007,\n",
       " 48087,\n",
       " 48081,\n",
       " 48060,\n",
       " 31264,\n",
       " 33001,\n",
       " 31239,\n",
       " 39100,\n",
       " 48037,\n",
       " 48007,\n",
       " 33061,\n",
       " 20901,\n",
       " 48086,\n",
       " 39081,\n",
       " 48052,\n",
       " 39066,\n",
       " 33062,\n",
       " 33048,\n",
       " 39057,\n",
       " 39088,\n",
       " 39049,\n",
       " 20003,\n",
       " 39063,\n",
       " 48030,\n",
       " 17105,\n",
       " 33052,\n",
       " 15027,\n",
       " 39034,\n",
       " 48915,\n",
       " 31153,\n",
       " 39101,\n",
       " 48912,\n",
       " 33003,\n",
       " 15068,\n",
       " 48008,\n",
       " 20027,\n",
       " 39078,\n",
       " 20016,\n",
       " 27015,\n",
       " 39072,\n",
       " 31082,\n",
       " 15003,\n",
       " 39098,\n",
       " 31259,\n",
       " 48022,\n",
       " 48051,\n",
       " 15040,\n",
       " 15014,\n",
       " 33027,\n",
       " 15001,\n",
       " 27029,\n",
       " 39026,\n",
       " 48097,\n",
       " 39082,\n",
       " 48092,\n",
       " 48055,\n",
       " 27010,\n",
       " 20002,\n",
       " 39014,\n",
       " 39003,\n",
       " 33058,\n",
       " 20028,\n",
       " 31024,\n",
       " 31022,\n",
       " 20014,\n",
       " 48039,\n",
       " 33067,\n",
       " 27053,\n",
       " 15029,\n",
       " 33050,\n",
       " 20075,\n",
       " 48058,\n",
       " 48019,\n",
       " 39083,\n",
       " 20048,\n",
       " 39004,\n",
       " 33015,\n",
       " 27022,\n",
       " 48065,\n",
       " 48042,\n",
       " 48910,\n",
       " 20006,\n",
       " 31117,\n",
       " 48095,\n",
       " 39022,\n",
       " 48094,\n",
       " 20046,\n",
       " 31226,\n",
       " 20066,\n",
       " 1042,\n",
       " 20010,\n",
       " 15024,\n",
       " 39097,\n",
       " 39086,\n",
       " 20041,\n",
       " 39089,\n",
       " 39055,\n",
       " 48006,\n",
       " 39046,\n",
       " 48025,\n",
       " 27046,\n",
       " 48050,\n",
       " 24116,\n",
       " 39015,\n",
       " 33053,\n",
       " 33072,\n",
       " 48005,\n",
       " 20023,\n",
       " 27007,\n",
       " 48026,\n",
       " 20031,\n",
       " 31087,\n",
       " 24106,\n",
       " 48059,\n",
       " 20033,\n",
       " 20021,\n",
       " 20020,\n",
       " 31054,\n",
       " 48023,\n",
       " 27035,\n",
       " 39013,\n",
       " 31221,\n",
       " 48091,\n",
       " 20004,\n",
       " 31129,\n",
       " 15016,\n",
       " 20050,\n",
       " 15032,\n",
       " 20022,\n",
       " 31263,\n",
       " 27018,\n",
       " 1004,\n",
       " 48093,\n",
       " 27056,\n",
       " 39010,\n",
       " 31081,\n",
       " 20907,\n",
       " 15047,\n",
       " 39071,\n",
       " 48075,\n",
       " 15052,\n",
       " 20054,\n",
       " 27039,\n",
       " 39053,\n",
       " 20007,\n",
       " 20005,\n",
       " 9410,\n",
       " 33068,\n",
       " 15093,\n",
       " 48024,\n",
       " 20011,\n",
       " 39039,\n",
       " 20044,\n",
       " 20060,\n",
       " 9214,\n",
       " 31248,\n",
       " 31213,\n",
       " 15084,\n",
       " 31137,\n",
       " 20052,\n",
       " 31102,\n",
       " 31090,\n",
       " 1010,\n",
       " 39051,\n",
       " 20035,\n",
       " 31031,\n",
       " 20905,\n",
       " 31149,\n",
       " 39050,\n",
       " 9124,\n",
       " 20904,\n",
       " 20047,\n",
       " 15090,\n",
       " 31020,\n",
       " 20906,\n",
       " 20012,\n",
       " 39077,\n",
       " 39096,\n",
       " 9215,\n",
       " 1003,\n",
       " 20042,\n",
       " 39070,\n",
       " 20037,\n",
       " 20038,\n",
       " 24096,\n",
       " 20001,\n",
       " 20008,\n",
       " 20062,\n",
       " 48072,\n",
       " 15038,\n",
       " 24001,\n",
       " 20078,\n",
       " 9189,\n",
       " 33028,\n",
       " 27011,\n",
       " 27020,\n",
       " 20058,\n",
       " 48088,\n",
       " 31049,\n",
       " 31055,\n",
       " 24025,\n",
       " 15088,\n",
       " 20057,\n",
       " 9216,\n",
       " 20034,\n",
       " 39017,\n",
       " 39032,\n",
       " 15086,\n",
       " 20026,\n",
       " 20043,\n",
       " 31211,\n",
       " 15034,\n",
       " 20070,\n",
       " 15010,\n",
       " 24121,\n",
       " 27004,\n",
       " 31908,\n",
       " 31236,\n",
       " 20015,\n",
       " 31140,\n",
       " 48074,\n",
       " 9025,\n",
       " 31144,\n",
       " 31058,\n",
       " 34904,\n",
       " 20068,\n",
       " 9908,\n",
       " 15066,\n",
       " 1063,\n",
       " 31017,\n",
       " 20025,\n",
       " 24130,\n",
       " 24020,\n",
       " 24177,\n",
       " 39065,\n",
       " 1054,\n",
       " 24145,\n",
       " 9413,\n",
       " 1018,\n",
       " 15083,\n",
       " 31126,\n",
       " 39027,\n",
       " 31196,\n",
       " 27034,\n",
       " 24037,\n",
       " 9012,\n",
       " 31033,\n",
       " 24029,\n",
       " 31098,\n",
       " 24129,\n",
       " 31115,\n",
       " 31256,\n",
       " 31034,\n",
       " 15028,\n",
       " 31092,\n",
       " 33022,\n",
       " 31186,\n",
       " 34134,\n",
       " 15045,\n",
       " 24901,\n",
       " 9903,\n",
       " 27014,\n",
       " 9190,\n",
       " 34036,\n",
       " 31112,\n",
       " 24164,\n",
       " 9209,\n",
       " 15006,\n",
       " 34185,\n",
       " 31127,\n",
       " 31037,\n",
       " 31028,\n",
       " 31138,\n",
       " 31123,\n",
       " 9050,\n",
       " 31904,\n",
       " 31025,\n",
       " 1013,\n",
       " 31027,\n",
       " 31133,\n",
       " 31084,\n",
       " 34027,\n",
       " 31185,\n",
       " 15037,\n",
       " 31003,\n",
       " 31004,\n",
       " 24060,\n",
       " 9213,\n",
       " 9409,\n",
       " 31136,\n",
       " 9011,\n",
       " 1009,\n",
       " 31199,\n",
       " 24120,\n",
       " 27901,\n",
       " 31044,\n",
       " 31247,\n",
       " 34160,\n",
       " 31130,\n",
       " 27023,\n",
       " 31093,\n",
       " 31134,\n",
       " 31240,\n",
       " 24194,\n",
       " 31188,\n",
       " 1061,\n",
       " 39092,\n",
       " 24112,\n",
       " 24109,\n",
       " 31189,\n",
       " 34110,\n",
       " 31091,\n",
       " 39093,\n",
       " 1053,\n",
       " 27040,\n",
       " 1020,\n",
       " 31073,\n",
       " 27012,\n",
       " 24179,\n",
       " 31198,\n",
       " 15085,\n",
       " 24021,\n",
       " 34056,\n",
       " 27026,\n",
       " 31128,\n",
       " 24114,\n",
       " 31095,\n",
       " 27006,\n",
       " 9416,\n",
       " 1051,\n",
       " 31118,\n",
       " 31101,\n",
       " 1055,\n",
       " 15079,\n",
       " 1021,\n",
       " 24193,\n",
       " 24101,\n",
       " 34158,\n",
       " 24012,\n",
       " 24098,\n",
       " 1001,\n",
       " 9192,\n",
       " 27043,\n",
       " 25063,\n",
       " 31131,\n",
       " 24137,\n",
       " 31222,\n",
       " 25045,\n",
       " 31245,\n",
       " 34199,\n",
       " 31906,\n",
       " 1027,\n",
       " 15020,\n",
       " 24110,\n",
       " 9217,\n",
       " 1901,\n",
       " 34067,\n",
       " 24199,\n",
       " 15012,\n",
       " 24183,\n",
       " 24068,\n",
       " 25121,\n",
       " 27037,\n",
       " 9014,\n",
       " 34171,\n",
       " 34049,\n",
       " 27049,\n",
       " 31210,\n",
       " 39094,\n",
       " 31119,\n",
       " 31013,\n",
       " 31193,\n",
       " 24056,\n",
       " 1049,\n",
       " 9394,\n",
       " 15007,\n",
       " 24134,\n",
       " 31252,\n",
       " 24040,\n",
       " 31085,\n",
       " 36059,\n",
       " 27032,\n",
       " 9412,\n",
       " 31075,\n",
       " 34080,\n",
       " 31113,\n",
       " 31076,\n",
       " 31019,\n",
       " 25059,\n",
       " 31111,\n",
       " 24118,\n",
       " 9102,\n",
       " 15089,\n",
       " 27003,\n",
       " 31083,\n",
       " 34032,\n",
       " 24167,\n",
       " 31143,\n",
       " 31021,\n",
       " 31262,\n",
       " 31243,\n",
       " 31154,\n",
       " 31100,\n",
       " 31241,\n",
       " 31214,\n",
       " 31253,\n",
       " 34135,\n",
       " 24132,\n",
       " 22204,\n",
       " 9361,\n",
       " 24070,\n",
       " 27042,\n",
       " 9276,\n",
       " 34151,\n",
       " 36020,\n",
       " 15074,\n",
       " 31109,\n",
       " 9134,\n",
       " 15042,\n",
       " 22028,\n",
       " 31158,\n",
       " 25031,\n",
       " 1056,\n",
       " 1902,\n",
       " 27062,\n",
       " 31052,\n",
       " 34100,\n",
       " 31132,\n",
       " 9328,\n",
       " 24151,\n",
       " 31120,\n",
       " 25247,\n",
       " 31237,\n",
       " 1037,\n",
       " 22901,\n",
       " 25057,\n",
       " 22106,\n",
       " 9109,\n",
       " 9238,\n",
       " 9068,\n",
       " 31905,\n",
       " 24076,\n",
       " 24019,\n",
       " 27055,\n",
       " 24133,\n",
       " 24083,\n",
       " 24158,\n",
       " 9054,\n",
       " 31002,\n",
       " 27045,\n",
       " 24196,\n",
       " 24052,\n",
       " 22170,\n",
       " 1006,\n",
       " 34214,\n",
       " 34114,\n",
       " 24184,\n",
       " 34124,\n",
       " 31059,\n",
       " 31181,\n",
       " 9415,\n",
       " 31121,\n",
       " 15033,\n",
       " 31260,\n",
       " 9255,\n",
       " 36044,\n",
       " 27060,\n",
       " 9006,\n",
       " 1046,\n",
       " 34062,\n",
       " 22078,\n",
       " 9905,\n",
       " 9347,\n",
       " 31242,\n",
       " 1047,\n",
       " 31147,\n",
       " 24102,\n",
       " 24061,\n",
       " 31246,\n",
       " 9395,\n",
       " 25025,\n",
       " 31011,\n",
       " 34170,\n",
       " 22032,\n",
       " 24009,\n",
       " 31139,\n",
       " 9244,\n",
       " 31172,\n",
       " 9045,\n",
       " 25243,\n",
       " 24169,\n",
       " 22131,\n",
       " 31265,\n",
       " 36056,\n",
       " 31228,\n",
       " 15018,\n",
       " 31056,\n",
       " 1017,\n",
       " 9329,\n",
       " 31039,\n",
       " 34107,\n",
       " 22122,\n",
       " 31180,\n",
       " 9306,\n",
       " 31007,\n",
       " 24201,\n",
       " 24104,\n",
       " 22006,\n",
       " 1014,\n",
       " 34139,\n",
       " 9230,\n",
       " 31209,\n",
       " 34073,\n",
       " 31124,\n",
       " 22250,\n",
       " 31183,\n",
       " 9077,\n",
       " 31071,\n",
       " 31168,\n",
       " 31074,\n",
       " 31234,\n",
       " 9220,\n",
       " 34140,\n",
       " 31206,\n",
       " 31089,\n",
       " 34028,\n",
       " 31161,\n",
       " 50232,\n",
       " 9283,\n",
       " 9175,\n",
       " 24143,\n",
       " 9120,\n",
       " 36010,\n",
       " 9272,\n",
       " 24198,\n",
       " 24123,\n",
       " 1062,\n",
       " 34005,\n",
       " 9060,\n",
       " 31257,\n",
       " 34093,\n",
       " 24004,\n",
       " 22068,\n",
       " 31014,\n",
       " 31018,\n",
       " 31229,\n",
       " 31041,\n",
       " 9016,\n",
       " 31177,\n",
       " 24063,\n",
       " 31159,\n",
       " 31238,\n",
       " 24163,\n",
       " 36047,\n",
       " 24171,\n",
       " 9057,\n",
       " 9454,\n",
       " 31148,\n",
       " 27024,\n",
       " 27058,\n",
       " 31001,\n",
       " 34179,\n",
       " 9043,\n",
       " 31150,\n",
       " 31125,\n",
       " 31116,\n",
       " 34129,\n",
       " 1044,\n",
       " 24071,\n",
       " 31166,\n",
       " 24007,\n",
       " 9115,\n",
       " 34068,\n",
       " 31184,\n",
       " 34037,\n",
       " 31182,\n",
       " 31192,\n",
       " 25024,\n",
       " 9251,\n",
       " 24092,\n",
       " 24210,\n",
       " 9135,\n",
       " 22057,\n",
       " 36015,\n",
       " 31204,\n",
       " 22086,\n",
       " 9422,\n",
       " 50245,\n",
       " 34154,\n",
       " 31162,\n",
       " 31063,\n",
       " 25086,\n",
       " 31255,\n",
       " 31167,\n",
       " 22059,\n",
       " 26045,\n",
       " 9052,\n",
       " 1016,\n",
       " 1030,\n",
       " 27008,\n",
       " 34020,\n",
       " 24079,\n",
       " 9195,\n",
       " 24064,\n",
       " 9001,\n",
       " 31190,\n",
       " 26065,\n",
       " 31170,\n",
       " 9423,\n",
       " 25123,\n",
       " 24027,\n",
       " 9398,\n",
       " 31200,\n",
       " 31261,\n",
       " 22253,\n",
       " 31005,\n",
       " 31155,\n",
       " 34061,\n",
       " 24055,\n",
       " 24057,\n",
       " 31099,\n",
       " 9906,\n",
       " 26062,\n",
       " 31225,\n",
       " 31008,\n",
       " 31174,\n",
       " 31160,\n",
       " 24011,\n",
       " 26166,\n",
       " 34113,\n",
       " 31043,\n",
       " 31230,\n",
       " 24209,\n",
       " 31146,\n",
       " 31175,\n",
       " 31030,\n",
       " 34190,\n",
       " 22054,\n",
       " 31141,\n",
       " 22069,\n",
       " 9485,\n",
       " 22076,\n",
       " 31045,\n",
       " 9013,\n",
       " 31046,\n",
       " 26033,\n",
       " 31197,\n",
       " 31114,\n",
       " 24030,\n",
       " 31096,\n",
       " 31080,\n",
       " 24170,\n",
       " 34083,\n",
       " 24175,\n",
       " 25903,\n",
       " 25087,\n",
       " 31009,\n",
       " 36018,\n",
       " 1019,\n",
       " 34176,\n",
       " 31038,\n",
       " 22114,\n",
       " 9149,\n",
       " 31135,\n",
       " 1028,\n",
       " 9007,\n",
       " 9265,\n",
       " 31036,\n",
       " 27017,\n",
       " 26128,\n",
       " 9408,\n",
       " 22207,\n",
       " 31079,\n",
       " 22107,\n",
       " 24039,\n",
       " 9280,\n",
       " 50035,\n",
       " 9227,\n",
       " 50168,\n",
       " 25901,\n",
       " 22227,\n",
       " 31103,\n",
       " 36040,\n",
       " 26063,\n",
       " 24034,\n",
       " 24059,\n",
       " 24049,\n",
       " 34136,\n",
       " 9373,\n",
       " 9071,\n",
       " 34122,\n",
       " 9323,\n",
       " 31216,\n",
       " 24180,\n",
       " 22200,\n",
       " 25082,\n",
       " 26013,\n",
       " 34041,\n",
       " 9419,\n",
       " 26001,\n",
       " 31029,\n",
       " 36016,\n",
       " 1023,\n",
       " 1052,\n",
       " 1060,\n",
       " 24213,\n",
       " 31012,\n",
       " 22182,\n",
       " 31151,\n",
       " 1034,\n",
       " 31207,\n",
       " 50268,\n",
       " 34208,\n",
       " 31094,\n",
       " 26049,\n",
       " 36901,\n",
       " 1032,\n",
       " 31026,\n",
       " 26142,\n",
       " 22902,\n",
       " 24214,\n",
       " 36032,\n",
       " 31047,\n",
       " 22208,\n",
       " 24226,\n",
       " 34202,\n",
       " 31035,\n",
       " 31142,\n",
       " 26155,\n",
       " 27047,\n",
       " 24038,\n",
       " 1031,\n",
       " 31219,\n",
       " 9327,\n",
       " 9334,\n",
       " 31231,\n",
       " 34245,\n",
       " 22221,\n",
       " 31061,\n",
       " 26068,\n",
       " 50041,\n",
       " 25017,\n",
       " 9298,\n",
       " 1057,\n",
       " 22189,\n",
       " 26042,\n",
       " 22249,\n",
       " 26131,\n",
       " 24103,\n",
       " 26148,\n",
       " 1041,\n",
       " 26034,\n",
       " 24162,\n",
       " 36007,\n",
       " 26111,\n",
       " 34161,\n",
       " 26056,\n",
       " 24093,\n",
       " 24100,\n",
       " 9482,\n",
       " 24229,\n",
       " 24173,\n",
       " 24225,\n",
       " 34234,\n",
       " 1011,\n",
       " 50210,\n",
       " 1039,\n",
       " 9143,\n",
       " 34222,\n",
       " 31053,\n",
       " 26127,\n",
       " 36002,\n",
       " 24105,\n",
       " 26109,\n",
       " 34168,\n",
       " 34218,\n",
       " 31110,\n",
       " 31217,\n",
       " 32035,\n",
       " 31069,\n",
       " 22209,\n",
       " 34157,\n",
       " 9172,\n",
       " 22095,\n",
       " 15080,\n",
       " 50270,\n",
       " 24227,\n",
       " 24205,\n",
       " 27041,\n",
       " 27009,\n",
       " 36028,\n",
       " 9317,\n",
       " 26180,\n",
       " 9427,\n",
       " 34229,\n",
       " 25221,\n",
       " 31251,\n",
       " 1022,\n",
       " 9166,\n",
       " 9088,\n",
       " 36046,\n",
       " 24159,\n",
       " 22084,\n",
       " 50186,\n",
       " 26025,\n",
       " 26043,\n",
       " 9310,\n",
       " 24119,\n",
       " 22044,\n",
       " 34228,\n",
       " 24095,\n",
       " 24065,\n",
       " 31235,\n",
       " 34169,\n",
       " 1043,\n",
       " 25043,\n",
       " 26087,\n",
       " 22144,\n",
       " 9273,\n",
       " 26073,\n",
       " 9036,\n",
       " 26154,\n",
       " 24219,\n",
       " 24015,\n",
       " 32061,\n",
       " 26129,\n",
       " 24094,\n",
       " 24023,\n",
       " 25089,\n",
       " 50248,\n",
       " 22062,\n",
       " 22109,\n",
       " 25126,\n",
       " 26048,\n",
       " 1033,\n",
       " 26150,\n",
       " 31145,\n",
       " 26167,\n",
       " 24156,\n",
       " 24022,\n",
       " 9098,\n",
       " 24041,\n",
       " 50128,\n",
       " 22252,\n",
       " 9382,\n",
       " 34025,\n",
       " 31171,\n",
       " 9083,\n",
       " 31152,\n",
       " 9902,\n",
       " 24197,\n",
       " ...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[40214, 2024, 10064, 40179, 26061]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from node2vec import Node2Vec\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "# Load the dataset from backoffice\n",
    "df_pueblos = pd.read_csv(\"../../data/end_product_data/pueblos_recommender.csv\")\n",
    "\n",
    "pueblos_cmun = df_pueblos['cmun'].tolist()\n",
    "\n",
    "# Load the dataset from user chosen villages\n",
    "user_files = os.listdir(\"../../data/user_output/\")\n",
    "\n",
    "user_choices = []\n",
    "\n",
    "# Get all files from the user_output directory\n",
    "\n",
    "# Read each file into a DataFrame and add to the list\n",
    "for file in user_files:\n",
    "    file_path = os.path.join(\"../../data/user_output/\", file)\n",
    "    user_df = pd.read_csv(file_path)\n",
    "    user_choices.append(user_df)\n",
    "\n",
    "# user choices of first user\n",
    "user_choices_cmun = user_choices[0].cmun.tolist()\n",
    "display(pueblos_cmun)\n",
    "display(user_choices_cmun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_scaled__total_population</th>\n",
       "      <th>enc_scaled__female</th>\n",
       "      <th>enc_scaled__score_connectivity</th>\n",
       "      <th>enc_scaled__score_economy</th>\n",
       "      <th>enc_scaled__score_area_economy</th>\n",
       "      <th>enc_scaled__score_hospital_distance</th>\n",
       "      <th>enc_scaled__score_area_hospital</th>\n",
       "      <th>enc_scaled__score_school_distance</th>\n",
       "      <th>enc_scaled__score_area_school</th>\n",
       "      <th>enc_scaled__score_transport</th>\n",
       "      <th>enc_scaled__score_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.558674</td>\n",
       "      <td>-0.559137</td>\n",
       "      <td>1.079668</td>\n",
       "      <td>-0.400296</td>\n",
       "      <td>-0.400296</td>\n",
       "      <td>1.817426</td>\n",
       "      <td>1.817426</td>\n",
       "      <td>-0.265322</td>\n",
       "      <td>-0.265322</td>\n",
       "      <td>-0.619807</td>\n",
       "      <td>0.391722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.860713</td>\n",
       "      <td>2.837166</td>\n",
       "      <td>1.051989</td>\n",
       "      <td>2.953534</td>\n",
       "      <td>2.953534</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>-0.265322</td>\n",
       "      <td>-0.265322</td>\n",
       "      <td>0.465618</td>\n",
       "      <td>1.059229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491932</td>\n",
       "      <td>0.488188</td>\n",
       "      <td>1.079668</td>\n",
       "      <td>-0.400296</td>\n",
       "      <td>-0.400296</td>\n",
       "      <td>-0.505430</td>\n",
       "      <td>-0.505430</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>1.764167</td>\n",
       "      <td>-0.026148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.077198</td>\n",
       "      <td>0.096428</td>\n",
       "      <td>1.118743</td>\n",
       "      <td>0.593067</td>\n",
       "      <td>0.593067</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.740058</td>\n",
       "      <td>1.225439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.914535</td>\n",
       "      <td>0.873629</td>\n",
       "      <td>1.024311</td>\n",
       "      <td>0.524220</td>\n",
       "      <td>0.524220</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.133787</td>\n",
       "      <td>0.529041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enc_scaled__total_population  enc_scaled__female  \\\n",
       "0                     -0.558674           -0.559137   \n",
       "1                      2.860713            2.837166   \n",
       "2                      0.491932            0.488188   \n",
       "3                      0.077198            0.096428   \n",
       "4                      0.914535            0.873629   \n",
       "\n",
       "   enc_scaled__score_connectivity  enc_scaled__score_economy  \\\n",
       "0                        1.079668                  -0.400296   \n",
       "1                        1.051989                   2.953534   \n",
       "2                        1.079668                  -0.400296   \n",
       "3                        1.118743                   0.593067   \n",
       "4                        1.024311                   0.524220   \n",
       "\n",
       "   enc_scaled__score_area_economy  enc_scaled__score_hospital_distance  \\\n",
       "0                       -0.400296                             1.817426   \n",
       "1                        2.953534                            -0.892572   \n",
       "2                       -0.400296                            -0.505430   \n",
       "3                        0.593067                            -0.892572   \n",
       "4                        0.524220                            -0.892572   \n",
       "\n",
       "   enc_scaled__score_area_hospital  enc_scaled__score_school_distance  \\\n",
       "0                         1.817426                          -0.265322   \n",
       "1                        -0.892572                          -0.265322   \n",
       "2                        -0.505430                           0.719746   \n",
       "3                        -0.892572                           0.719746   \n",
       "4                        -0.892572                           0.719746   \n",
       "\n",
       "   enc_scaled__score_area_school  enc_scaled__score_transport  \\\n",
       "0                      -0.265322                    -0.619807   \n",
       "1                      -0.265322                     0.465618   \n",
       "2                       0.719746                     1.764167   \n",
       "3                       0.719746                     0.740058   \n",
       "4                       0.719746                     0.133787   \n",
       "\n",
       "   enc_scaled__score_age  \n",
       "0               0.391722  \n",
       "1               1.059229  \n",
       "2              -0.026148  \n",
       "3               1.225439  \n",
       "4               0.529041  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_scaled__total_population</th>\n",
       "      <th>enc_scaled__female</th>\n",
       "      <th>enc_scaled__score_connectivity</th>\n",
       "      <th>enc_scaled__score_economy</th>\n",
       "      <th>enc_scaled__score_area_economy</th>\n",
       "      <th>enc_scaled__score_hospital_distance</th>\n",
       "      <th>enc_scaled__score_area_hospital</th>\n",
       "      <th>enc_scaled__score_school_distance</th>\n",
       "      <th>enc_scaled__score_area_school</th>\n",
       "      <th>enc_scaled__score_transport</th>\n",
       "      <th>enc_scaled__score_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.557181</td>\n",
       "      <td>3.802348</td>\n",
       "      <td>-0.613597</td>\n",
       "      <td>4.173109</td>\n",
       "      <td>4.173109</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>5.792635</td>\n",
       "      <td>-0.473490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.865195</td>\n",
       "      <td>1.788261</td>\n",
       "      <td>0.820793</td>\n",
       "      <td>0.416032</td>\n",
       "      <td>0.416032</td>\n",
       "      <td>1.043140</td>\n",
       "      <td>1.043140</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>2.815405</td>\n",
       "      <td>0.672636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.560877</td>\n",
       "      <td>2.638127</td>\n",
       "      <td>0.544010</td>\n",
       "      <td>0.652079</td>\n",
       "      <td>0.652079</td>\n",
       "      <td>1.817426</td>\n",
       "      <td>1.817426</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>2.739097</td>\n",
       "      <td>0.136504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059098</td>\n",
       "      <td>0.101167</td>\n",
       "      <td>-1.261597</td>\n",
       "      <td>0.071797</td>\n",
       "      <td>0.071797</td>\n",
       "      <td>-0.118287</td>\n",
       "      <td>-0.118287</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>3.798159</td>\n",
       "      <td>-0.410759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.080038</td>\n",
       "      <td>2.202136</td>\n",
       "      <td>0.778462</td>\n",
       "      <td>1.271701</td>\n",
       "      <td>1.271701</td>\n",
       "      <td>0.268855</td>\n",
       "      <td>0.268855</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>2.550249</td>\n",
       "      <td>-0.029549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>3.610695</td>\n",
       "      <td>3.472196</td>\n",
       "      <td>1.024311</td>\n",
       "      <td>1.950336</td>\n",
       "      <td>1.950336</td>\n",
       "      <td>-0.505430</td>\n",
       "      <td>-0.505430</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.327924</td>\n",
       "      <td>1.572655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>0.522624</td>\n",
       "      <td>0.496086</td>\n",
       "      <td>0.571688</td>\n",
       "      <td>0.337350</td>\n",
       "      <td>0.337350</td>\n",
       "      <td>0.268855</td>\n",
       "      <td>0.268855</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>-1.010917</td>\n",
       "      <td>0.596693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6821</th>\n",
       "      <td>3.386409</td>\n",
       "      <td>3.300011</td>\n",
       "      <td>0.545638</td>\n",
       "      <td>2.294571</td>\n",
       "      <td>2.294571</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>-0.159224</td>\n",
       "      <td>1.345018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6822</th>\n",
       "      <td>1.622808</td>\n",
       "      <td>1.682423</td>\n",
       "      <td>1.079668</td>\n",
       "      <td>0.337350</td>\n",
       "      <td>0.337350</td>\n",
       "      <td>1.817426</td>\n",
       "      <td>1.817426</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>-0.842902</td>\n",
       "      <td>1.366077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6823</th>\n",
       "      <td>-0.614549</td>\n",
       "      <td>-0.620745</td>\n",
       "      <td>-0.541959</td>\n",
       "      <td>-0.400296</td>\n",
       "      <td>-0.400296</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>-0.892572</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.719746</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>-1.366208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6824 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      enc_scaled__total_population  enc_scaled__female  \\\n",
       "0                         3.557181            3.802348   \n",
       "1                         1.865195            1.788261   \n",
       "2                         2.560877            2.638127   \n",
       "3                         0.059098            0.101167   \n",
       "4                         2.080038            2.202136   \n",
       "...                            ...                 ...   \n",
       "6819                      3.610695            3.472196   \n",
       "6820                      0.522624            0.496086   \n",
       "6821                      3.386409            3.300011   \n",
       "6822                      1.622808            1.682423   \n",
       "6823                     -0.614549           -0.620745   \n",
       "\n",
       "      enc_scaled__score_connectivity  enc_scaled__score_economy  \\\n",
       "0                          -0.613597                   4.173109   \n",
       "1                           0.820793                   0.416032   \n",
       "2                           0.544010                   0.652079   \n",
       "3                          -1.261597                   0.071797   \n",
       "4                           0.778462                   1.271701   \n",
       "...                              ...                        ...   \n",
       "6819                        1.024311                   1.950336   \n",
       "6820                        0.571688                   0.337350   \n",
       "6821                        0.545638                   2.294571   \n",
       "6822                        1.079668                   0.337350   \n",
       "6823                       -0.541959                  -0.400296   \n",
       "\n",
       "      enc_scaled__score_area_economy  enc_scaled__score_hospital_distance  \\\n",
       "0                           4.173109                            -0.892572   \n",
       "1                           0.416032                             1.043140   \n",
       "2                           0.652079                             1.817426   \n",
       "3                           0.071797                            -0.118287   \n",
       "4                           1.271701                             0.268855   \n",
       "...                              ...                                  ...   \n",
       "6819                        1.950336                            -0.505430   \n",
       "6820                        0.337350                             0.268855   \n",
       "6821                        2.294571                            -0.892572   \n",
       "6822                        0.337350                             1.817426   \n",
       "6823                       -0.400296                            -0.892572   \n",
       "\n",
       "      enc_scaled__score_area_hospital  enc_scaled__score_school_distance  \\\n",
       "0                           -0.892572                           0.719746   \n",
       "1                            1.043140                           0.719746   \n",
       "2                            1.817426                           0.719746   \n",
       "3                           -0.118287                           0.719746   \n",
       "4                            0.268855                           0.719746   \n",
       "...                               ...                                ...   \n",
       "6819                        -0.505430                           0.719746   \n",
       "6820                         0.268855                           0.719746   \n",
       "6821                        -0.892572                           0.719746   \n",
       "6822                         1.817426                           0.719746   \n",
       "6823                        -0.892572                           0.719746   \n",
       "\n",
       "      enc_scaled__score_area_school  enc_scaled__score_transport  \\\n",
       "0                          0.719746                     5.792635   \n",
       "1                          0.719746                     2.815405   \n",
       "2                          0.719746                     2.739097   \n",
       "3                          0.719746                     3.798159   \n",
       "4                          0.719746                     2.550249   \n",
       "...                             ...                          ...   \n",
       "6819                       0.719746                     0.327924   \n",
       "6820                       0.719746                    -1.010917   \n",
       "6821                       0.719746                    -0.159224   \n",
       "6822                       0.719746                    -0.842902   \n",
       "6823                       0.719746                     0.474300   \n",
       "\n",
       "      enc_scaled__score_age  \n",
       "0                 -0.473490  \n",
       "1                  0.672636  \n",
       "2                  0.136504  \n",
       "3                 -0.410759  \n",
       "4                 -0.029549  \n",
       "...                     ...  \n",
       "6819               1.572655  \n",
       "6820               0.596693  \n",
       "6821               1.345018  \n",
       "6822               1.366077  \n",
       "6823              -1.366208  \n",
       "\n",
       "[6824 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pueblos_enc = df_pueblos.filter(regex=r\"^enc_\", axis=1)\n",
    "# Select only numerical features with more than 2 unique values (non-binary features)\n",
    "pueblos_numerical_features = df_pueblos_enc.loc[:, (df_pueblos_enc.nunique() > 2)]\n",
    "\n",
    "# Process user choices: filter for encoded features and remove binary columns\n",
    "processed_user_choices = []\n",
    "for df in user_choices:\n",
    "    df_filtered = df.filter(regex=r\"^enc_\", axis=1)\n",
    "    df_non_binary = df_filtered.loc[:, ~(df_filtered.isin([0.0, 1.0]).all())]\n",
    "    processed_user_choices.append(df_non_binary)\n",
    "\n",
    "display(processed_user_choices[0])\n",
    "display(pueblos_numerical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1️⃣ Construct the Graph\n",
    "G = nx.Graph()\n",
    "for i, row in pueblos_numerical_features.iterrows():\n",
    "    # get cmun of row\n",
    "    cmun = df_pueblos.iloc[i, 0]\n",
    "    G.add_node(cmun, **row.to_dict())\n",
    "\n",
    "# Compute pairwise feature similarity (Cosine Similarity)\n",
    "feature_matrix = pueblos_numerical_features\n",
    "similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "display(len(feature_matrix))\n",
    "\n",
    "# Add edges based on similarity threshold\n",
    "threshold = 0.9  # Adjust threshold based on data distribution\n",
    "# Use batching for edge creation to avoid memory issues\n",
    "batch_size = 2000\n",
    "for i in range(len(feature_matrix)):\n",
    "    for j in range(i + 1, min(i + batch_size, len(feature_matrix))):\n",
    "        if similarity_matrix[i, j] > threshold:\n",
    "            G.add_edge(i, j, weight=similarity_matrix[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 12289/12289 [00:01<00:00, 8555.58it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:00<00:00,  8.67it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:00<00:00,  9.11it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:00<00:00,  9.01it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:00<00:00,  9.04it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 2/2 [00:00<00:00,  9.21it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 2/2 [00:00<00:00,  9.01it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 2/2 [00:00<00:00,  9.33it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:00<00:00,  9.44it/s]\n",
      "Generating walks (CPU: 11): 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]\n",
      "Generating walks (CPU: 12): 100%|██████████| 1/1 [00:00<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 16, Silhouette Score: 0.5016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 12289/12289 [00:01<00:00, 7487.62it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:00<00:00,  8.86it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:00<00:00,  9.22it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:00<00:00,  9.23it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:00<00:00,  9.18it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 2/2 [00:00<00:00,  9.35it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 2/2 [00:00<00:00,  7.98it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 2/2 [00:00<00:00,  9.26it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 2/2 [00:00<00:00,  9.42it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:00<00:00,  9.24it/s]\n",
      "Generating walks (CPU: 11): 100%|██████████| 1/1 [00:00<00:00,  9.26it/s]\n",
      "Generating walks (CPU: 12): 100%|██████████| 1/1 [00:00<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 24, Silhouette Score: 0.4950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 12289/12289 [00:01<00:00, 8007.71it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:00<00:00,  7.76it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:00<00:00,  8.53it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:00<00:00,  9.15it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:00<00:00,  9.25it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 2/2 [00:00<00:00,  7.93it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 2/2 [00:00<00:00,  8.76it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 2/2 [00:00<00:00,  8.55it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 2/2 [00:00<00:00,  9.32it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:00<00:00,  9.24it/s]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
      "Generating walks (CPU: 11): 100%|██████████| 1/1 [00:00<00:00,  9.17it/s]\n",
      "Generating walks (CPU: 12): 100%|██████████| 1/1 [00:00<00:00,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 32, Silhouette Score: 0.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 12289/12289 [00:01<00:00, 7736.09it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:00<00:00,  9.23it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:00<00:00,  7.85it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:00<00:00,  9.19it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:00<00:00,  8.45it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 2/2 [00:00<00:00,  9.03it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 2/2 [00:00<00:00,  8.93it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 2/2 [00:00<00:00,  8.72it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 2/2 [00:00<00:00,  8.94it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:00<00:00,  8.91it/s]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n",
      "Generating walks (CPU: 11): 100%|██████████| 1/1 [00:00<00:00,  9.28it/s]\n",
      "Generating walks (CPU: 12): 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 48, Silhouette Score: 0.4936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 12289/12289 [00:01<00:00, 7845.25it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:00<00:00,  9.19it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:00<00:00,  9.21it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:00<00:00,  9.27it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:00<00:00,  9.16it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 2/2 [00:00<00:00,  8.99it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 2/2 [00:00<00:00,  7.67it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 2/2 [00:00<00:00,  8.24it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 2/2 [00:00<00:00,  9.43it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:00<00:00,  8.49it/s]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n",
      "Generating walks (CPU: 11): 100%|██████████| 1/1 [00:00<00:00,  9.17it/s]\n",
      "Generating walks (CPU: 12): 100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 64, Silhouette Score: 0.4947\n",
      "Best dimension: 16\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import silhouette_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Test different dimensions\n",
    "# dimensions_to_test = [16, 24, 32, 48, 64]\n",
    "# scores = []\n",
    "\n",
    "# for dim in dimensions_to_test:\n",
    "#     # Create and train model\n",
    "#     node2vec = Node2Vec(G, dimensions=dim, walk_length=10, num_walks=20, workers=12)\n",
    "#     model = node2vec.fit(window=5, min_count=1)\n",
    "    \n",
    "#     # Extract embeddings\n",
    "#     embeddings = np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "    \n",
    "#     # Evaluate using silhouette score (requires clustering)\n",
    "#     from sklearn.cluster import KMeans\n",
    "#     kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "#     clusters = kmeans.fit_predict(embeddings)\n",
    "#     score = silhouette_score(embeddings, clusters)\n",
    "    \n",
    "#     scores.append((dim, score))\n",
    "#     print(f\"Dimensions: {dim}, Silhouette Score: {score:.4f}\")\n",
    "\n",
    "# # Find best dimension\n",
    "# best_dim = max(scores, key=lambda x: x[1])[0]\n",
    "# print(f\"Best dimension: {best_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 12928/12928 [00:43<00:00, 297.14it/s] \n",
      "Generating walks (CPU: 1): 100%|██████████| 17/17 [00:09<00:00,  1.87it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 17/17 [00:09<00:00,  1.88it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 17/17 [00:09<00:00,  1.88it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 17/17 [00:09<00:00,  1.89it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 16/16 [00:08<00:00,  1.90it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 16/16 [00:08<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2️⃣ Generate Node2Vec Embeddings\n",
    "node2vec = Node2Vec(G, dimensions=16, walk_length=15, num_walks=100, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = node2vec.fit(\n",
    "    window=5,    \n",
    "    min_count=1, \n",
    "    batch_words=50,  \n",
    "    epochs=5,    \n",
    "    sg=0,            \n",
    "    hs=0,          \n",
    "    negative=7        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.723396  ,  0.69736333, ...,  0.72957946,\n",
       "         0.16038188, -0.06239642],\n",
       "       [ 0.723396  ,  1.        ,  0.96367783, ...,  0.52713098,\n",
       "         0.58274212, -0.31754954],\n",
       "       [ 0.69736333,  0.96367783,  1.        , ...,  0.54329762,\n",
       "         0.67090616, -0.37992173],\n",
       "       ...,\n",
       "       [ 0.72957946,  0.52713098,  0.54329762, ...,  1.        ,\n",
       "         0.51065835, -0.36601523],\n",
       "       [ 0.16038188,  0.58274212,  0.67090616, ...,  0.51065835,\n",
       "         1.        , -0.72235604],\n",
       "       [-0.06239642, -0.31754954, -0.37992173, ..., -0.36601523,\n",
       "        -0.72235604,  1.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../models/node2vec.model\n",
      "Graph saved to ../../models/village_graph.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../../models', exist_ok=True)\n",
    "\n",
    "# Save the Node2Vec embeddings\n",
    "model_path = '../../models/node2vec.model'\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# If you want to save the graph separately\n",
    "graph_path = '../../models/village_graph.pkl'\n",
    "with open(graph_path, 'wb') as f:\n",
    "    pickle.dump(G, f)\n",
    "    \n",
    "print(f\"Graph saved to {graph_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Do We Use node2vec If We Just Use Cosine Similarity Later?\n",
    "\n",
    "Good question! Here’s why:\n",
    "\n",
    "✅ node2vec learns embeddings that capture graph structure (community, structural similarities, etc.).\n",
    "✅ These embeddings are better than raw features for similarity because they encode relationships beyond direct numerical similarity.\n",
    "✅ Cosine similarity works on embeddings (not raw data), meaning it measures similarity in a meaningful latent space.\n",
    "\n",
    "So, node2vec transforms the problem:\n",
    "\n",
    "Instead of comparing raw village features, we compare graph-informed village embeddings using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score: 1.0000\n",
      "Top 10 Most Similar Villages:\n",
      "Village 2024: Similarity 0.9998\n",
      "Village 2234: Similarity 0.9972\n",
      "Village 1837: Similarity 0.9958\n",
      "Village 2279: Similarity 0.9890\n",
      "Village 2333: Similarity 0.9845\n",
      "Village 2034: Similarity 0.9826\n",
      "Village 1514: Similarity 0.9811\n",
      "Village 1833: Similarity 0.9800\n",
      "Village 1992: Similarity 0.9782\n",
      "Village 1896: Similarity 0.9658\n"
     ]
    }
   ],
   "source": [
    "# 3️⃣ Compute Similarity\n",
    "user_selected_villages = user_choices_cmun # Example selected villages\n",
    "selected_vectors = [model.wv[str(v)] for v in user_selected_villages]\n",
    "centroid_vector = np.mean(selected_vectors, axis=0)\n",
    "\n",
    "# Rank all villages based on cosine similarity\n",
    "all_village_vectors = {v: model.wv[str(v)] for v in G.nodes()}\n",
    "similarities = {v: cosine_similarity([centroid_vector], [vec])[0][0] for v, vec in all_village_vectors.items()}\n",
    "ranked_villages = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 4️⃣ Evaluate Ranking Quality\n",
    "def ndcg_at_k(ranked_list, ideal_list, k):\n",
    "    def dcg(scores):\n",
    "        return sum([(2**s - 1) / np.log2(i+2) for i, s in enumerate(scores)])\n",
    "    \n",
    "    ideal_scores = [1 if v in ideal_list else 0 for v, _ in ranked_list[:k]]\n",
    "    return dcg(ideal_scores) / dcg(sorted(ideal_scores, reverse=True))\n",
    "\n",
    "ndcg_score = ndcg_at_k(ranked_villages, user_selected_villages, k=10)\n",
    "print(f\"NDCG Score: {ndcg_score:.4f}\")\n",
    "\n",
    "# Display top similar villages\n",
    "print(\"Top 10 Most Similar Villages:\")\n",
    "for village, score in ranked_villages[:10]:\n",
    "    print(f\"Village {village}: Similarity {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w9/bt5d4t050m7fd91t2r7l1mlh0000gn/T/ipykernel_35551/3696273799.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=village_ids, y=similarity_scores, palette=\"viridis\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Extract top 10 similar villages and their scores\n",
    "top_villages = ranked_villages[:10]\n",
    "village_ids = [v for v, _ in top_villages]\n",
    "similarity_scores = [s for _, s in top_villages]\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=village_ids, y=similarity_scores, palette=\"viridis\")\n",
    "plt.xlabel(\"Village ID\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.title(\"Top 10 Most Similar Villages to User Profile Centroid\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Graph Density\n",
    "Graph density tells us how connected the graph is.\n",
    "A fully connected graph has density 1, while a sparse graph has density close to 0.\n",
    "\n",
    "If density > 0.1, your graph might be too dense.\n",
    "If density < 0.01, it might be too sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Density: 0.0516\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "density = nx.density(G)\n",
    "print(f\"Graph Density: {density:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGraph visualization: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(H.nodes())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m nodes and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(H.edges())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m edges\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Basic usage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43mplot_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# For large graphs, use a sample\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# plot_graph(G, sample=100, title=\"Sampled Village Network\")\u001b[39;00m\n\u001b[32m     62\u001b[39m \n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# More detailed visualization\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_detailed_graph\u001b[39m(G, figsize=(\u001b[32m14\u001b[39m, \u001b[32m12\u001b[39m), node_feature=\u001b[38;5;28;01mNone\u001b[39;00m, highlight_nodes=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mplot_graph\u001b[39m\u001b[34m(G, figsize, node_size, sample, title)\u001b[39m\n\u001b[32m     29\u001b[39m     pos = nx.spring_layout(H, seed=\u001b[32m42\u001b[39m)  \u001b[38;5;66;03m# Force-directed layout\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     pos = \u001b[43mnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkamada_kawai_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Better for larger graphs\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Get node degrees for sizing (optional)\u001b[39;00m\n\u001b[32m     34\u001b[39m node_degrees = \u001b[38;5;28mdict\u001b[39m(H.degree())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/networkx/drawing/layout.py:713\u001b[39m, in \u001b[36mkamada_kawai_layout\u001b[39m\u001b[34m(G, dist, pos, weight, scale, center, dim)\u001b[39m\n\u001b[32m    710\u001b[39m         pos = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(G, np.linspace(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(G))))\n\u001b[32m    711\u001b[39m pos_arr = np.array([pos[n] \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m G])\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m pos = \u001b[43m_kamada_kawai_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist_mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    715\u001b[39m pos = rescale_layout(pos, scale=scale) + center\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(G, pos))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/networkx/drawing/layout.py:730\u001b[39m, in \u001b[36m_kamada_kawai_solve\u001b[39m\u001b[34m(dist_mtx, pos_arr, dim)\u001b[39m\n\u001b[32m    727\u001b[39m meanwt = \u001b[32m1e-3\u001b[39m\n\u001b[32m    728\u001b[39m costargs = (np, \u001b[32m1\u001b[39m / (dist_mtx + np.eye(dist_mtx.shape[\u001b[32m0\u001b[39m]) * \u001b[32m1e-3\u001b[39m), meanwt, dim)\n\u001b[32m--> \u001b[39m\u001b[32m730\u001b[39m optresult = \u001b[43msp\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_kamada_kawai_costfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpos_arr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcostargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m optresult.x.reshape((-\u001b[32m1\u001b[39m, dim))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/scipy/optimize/_minimize.py:713\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    710\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    711\u001b[39m                              **options)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    716\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    717\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:407\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[39m\n\u001b[32m    401\u001b[39m task_str = task.tobytes()\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task_str.startswith(\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFG\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    404\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    405\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    406\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task_str.startswith(\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNEW_X\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    409\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    410\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:296\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(x, \u001b[38;5;28mself\u001b[39m.x):\n\u001b[32m    295\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x_impl(x)\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad()\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m         \u001b[38;5;28mself\u001b[39m.f_updated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[39m, in \u001b[36mScalarFunction.__init__.<locals>.update_fun\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_fun\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28mself\u001b[39m.f = \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[39m, in \u001b[36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m fx = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isscalar(fx):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:79\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     78\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:73\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/networkx/drawing/layout.py:754\u001b[39m, in \u001b[36m_kamada_kawai_costfn\u001b[39m\u001b[34m(pos_vec, np, invdist, meanweight, dim)\u001b[39m\n\u001b[32m    751\u001b[39m offset[np.diag_indices(nNodes)] = \u001b[32m0\u001b[39m\n\u001b[32m    753\u001b[39m cost = \u001b[32m0.5\u001b[39m * np.sum(offset**\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m754\u001b[39m grad = np.einsum(\u001b[33m\"\u001b[39m\u001b[33mij,ij,ijk->ik\u001b[39m\u001b[33m\"\u001b[39m, invdist, offset, direction) - \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    755\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mij,ij,ijk->jk\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[38;5;66;03m# Additional parabolic term to encourage mean position to be near origin:\u001b[39;00m\n\u001b[32m    759\u001b[39m sumpos = np.sum(pos_arr, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/www/python/bootcamp/ml-pueblos/.venv/lib/python3.11/site-packages/numpy/core/einsumfunc.py:1371\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(out, optimize, *operands, **kwargs)\u001b[39m\n\u001b[32m   1369\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[32m   1370\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m] = out\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[32m   1375\u001b[39m valid_einsum_kwargs = [\u001b[33m'\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcasting\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def plot_graph(G, figsize=(12, 10), node_size=50, sample=None, title=\"Village Network Graph\"):\n",
    "    \"\"\"\n",
    "    Plot the graph G with various visualization options.\n",
    "    \n",
    "    Parameters:\n",
    "    - G: NetworkX graph\n",
    "    - figsize: Figure size tuple (width, height)\n",
    "    - node_size: Size of nodes in the plot\n",
    "    - sample: If provided, visualize only a sample of nodes (int or None)\n",
    "    - title: Plot title\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original graph\n",
    "    if sample is not None and sample < len(G.nodes()):\n",
    "        # Sample nodes if the graph is too large\n",
    "        nodes = list(G.nodes())\n",
    "        sampled_nodes = np.random.choice(nodes, size=sample, replace=False)\n",
    "        H = G.subgraph(sampled_nodes)\n",
    "    else:\n",
    "        H = G.copy()\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Choose a layout algorithm based on graph size\n",
    "    if len(H.nodes()) < 500:\n",
    "        pos = nx.spring_layout(H, seed=42)  # Force-directed layout\n",
    "    else:\n",
    "        pos = nx.kamada_kawai_layout(H)  # Better for larger graphs\n",
    "    \n",
    "    # Get node degrees for sizing (optional)\n",
    "    node_degrees = dict(H.degree())\n",
    "    node_sizes = [node_size * (1 + 0.5 * node_degrees[n]) for n in H.nodes()]\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx(\n",
    "        H,\n",
    "        pos=pos,\n",
    "        with_labels=False,  # Set to True for small graphs\n",
    "        node_size=node_sizes,\n",
    "        node_color=\"skyblue\",\n",
    "        edge_color=\"gray\",\n",
    "        alpha=0.8,\n",
    "        width=0.5\n",
    "    )\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Graph visualization: {len(H.nodes())} nodes and {len(H.edges())} edges\")\n",
    "    \n",
    "\n",
    "# Basic usage\n",
    "plot_graph(G)\n",
    "\n",
    "# For large graphs, use a sample\n",
    "# plot_graph(G, sample=100, title=\"Sampled Village Network\")\n",
    "\n",
    "# More detailed visualization\n",
    "def plot_detailed_graph(G, figsize=(14, 12), node_feature=None, highlight_nodes=None):\n",
    "    \"\"\"\n",
    "    Create a more detailed graph visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    - G: NetworkX graph\n",
    "    - figsize: Figure size tuple\n",
    "    - node_feature: Dictionary with node values for coloring (optional)\n",
    "    - highlight_nodes: List of nodes to highlight (optional)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Sample the graph if it's very large\n",
    "    if len(G.nodes()) > 1000:\n",
    "        H = G.subgraph(np.random.choice(list(G.nodes()), 500, replace=False))\n",
    "    else:\n",
    "        H = G\n",
    "    \n",
    "    pos = nx.spring_layout(H, seed=42)\n",
    "    \n",
    "    # Node colors based on communities or other features\n",
    "    if node_feature:\n",
    "        node_colors = [node_feature.get(node, 0) for node in H.nodes()]\n",
    "        cmap = plt.cm.viridis\n",
    "        vmin = min(node_colors)\n",
    "        vmax = max(node_colors)\n",
    "    else:\n",
    "        # Default coloring\n",
    "        node_colors = 'skyblue'\n",
    "        cmap = None\n",
    "        vmin = vmax = None\n",
    "    \n",
    "    # Basic nodes\n",
    "    nx.draw_networkx_nodes(\n",
    "        H, pos,\n",
    "        node_size=80,\n",
    "        node_color=node_colors,\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # Highlight specific nodes if provided\n",
    "    if highlight_nodes:\n",
    "        highlight_nodes = [n for n in highlight_nodes if n in H.nodes()]\n",
    "        if highlight_nodes:\n",
    "            nx.draw_networkx_nodes(\n",
    "                H, pos,\n",
    "                nodelist=highlight_nodes,\n",
    "                node_size=150,\n",
    "                node_color='red',\n",
    "                edgecolors='black',\n",
    "                linewidths=2\n",
    "            )\n",
    "    \n",
    "    # Draw edges with reduced opacity\n",
    "    nx.draw_networkx_edges(\n",
    "        H, pos,\n",
    "        width=0.3,\n",
    "        alpha=0.4,\n",
    "        edge_color='gray'\n",
    "    )\n",
    "    \n",
    "    # Add labels for a subset of nodes or important nodes\n",
    "    if len(H.nodes()) < 100:\n",
    "        nx.draw_networkx_labels(H, pos, font_size=8)\n",
    "    \n",
    "    plt.title(\"Village Network Visualization\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with highlight_nodes\n",
    "top_villages = [v[0] for v in ranked_villages[:5]]  # Top 5 villages from previous results\n",
    "plot_detailed_graph(G, highlight_nodes=top_villages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
